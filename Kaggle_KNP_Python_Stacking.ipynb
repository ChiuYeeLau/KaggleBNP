{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Thu Feb  4 06:20:12 2016\n",
    "\n",
    "@author: monkey\n",
    "\"\"\"\n",
    "# % pylab inline \n",
    "# % matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import csv\n",
    "import numpy as np\n",
    "import pdb\n",
    "from copy import deepcopy\n",
    "import random\n",
    "# import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "# from bayes_opt import BayesianOptimization\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data...\n"
     ]
    }
   ],
   "source": [
    "print('Load data...')\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "target = train['target']\n",
    "\n",
    "train_with_target = train.drop(['ID'], axis = 1)\n",
    "train = train.drop(['ID','target'],axis=1)\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "ids = test['ID'].values\n",
    "test = test.drop(['ID'],axis=1)\n",
    "\n",
    "# add number of nans\n",
    "train['number_NAN'] = train.isnull().sum(axis = 1)\n",
    "test['number_NAN'] = test.isnull().sum(axis = 1)\n",
    "train_with_target['number_NAN'] = train.isnull().sum(axis = 1)\n",
    "\n",
    "train_len = train.shape[0]\n",
    "test_len = test.shape[0]\n",
    "\n",
    "train = train.fillna(-1)\n",
    "test = test.fillna(-1)\n",
    "train_with_target = train_with_target.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train.columns == test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filter all object features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "object_features = []\n",
    "all_features = []\n",
    "for feat in train.columns:\n",
    "    if feat != 'number_NAN':\n",
    "        all_features.append(feat)\n",
    "    if train[feat].dtype == 'object':\n",
    "        object_features.append(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['v3', 'v22', 'v24', 'v30', 'v31', 'v47', 'v52', 'v56', 'v66', 'v71', 'v74', 'v75', 'v79', 'v91', 'v107', 'v110', 'v112', 'v113', 'v125', 'v38', 'v62', 'v72', 'v129']\n"
     ]
    }
   ],
   "source": [
    "object_features.extend(['v38', 'v62', 'v72', 'v129'])\n",
    "print object_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>v10</th>\n",
       "      <th>...</th>\n",
       "      <th>v123</th>\n",
       "      <th>v124</th>\n",
       "      <th>v125</th>\n",
       "      <th>v126</th>\n",
       "      <th>v127</th>\n",
       "      <th>v128</th>\n",
       "      <th>v129</th>\n",
       "      <th>v130</th>\n",
       "      <th>v131</th>\n",
       "      <th>number_NAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 1.335739</td>\n",
       "      <td> 8.727474</td>\n",
       "      <td> C</td>\n",
       "      <td> 3.921026</td>\n",
       "      <td> 7.915266</td>\n",
       "      <td> 2.599278</td>\n",
       "      <td> 3.176895</td>\n",
       "      <td> 0.012941</td>\n",
       "      <td>  9.999999</td>\n",
       "      <td> 0.503281</td>\n",
       "      <td>...</td>\n",
       "      <td> 1.989780</td>\n",
       "      <td> 0.035754</td>\n",
       "      <td> AU</td>\n",
       "      <td> 1.804126</td>\n",
       "      <td> 3.113719</td>\n",
       "      <td> 2.024285</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.636365</td>\n",
       "      <td> 2.857144</td>\n",
       "      <td>  1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td> C</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td> 9.191265</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td> 2.301630</td>\n",
       "      <td> -1.000000</td>\n",
       "      <td> 1.312910</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td> 0.598896</td>\n",
       "      <td> AF</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td> 1.957825</td>\n",
       "      <td> 0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td> 81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 0.943877</td>\n",
       "      <td> 5.310079</td>\n",
       "      <td> C</td>\n",
       "      <td> 4.410969</td>\n",
       "      <td> 5.326159</td>\n",
       "      <td> 3.979592</td>\n",
       "      <td> 3.928571</td>\n",
       "      <td> 0.019645</td>\n",
       "      <td> 12.666667</td>\n",
       "      <td> 0.765864</td>\n",
       "      <td>...</td>\n",
       "      <td> 2.477596</td>\n",
       "      <td> 0.013452</td>\n",
       "      <td> AE</td>\n",
       "      <td> 1.773709</td>\n",
       "      <td> 3.922193</td>\n",
       "      <td> 1.120468</td>\n",
       "      <td> 2</td>\n",
       "      <td> 0.883118</td>\n",
       "      <td> 1.176472</td>\n",
       "      <td>  2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         v1        v2 v3        v4        v5        v6        v7        v8  \\\n",
       "0  1.335739  8.727474  C  3.921026  7.915266  2.599278  3.176895  0.012941   \n",
       "1 -1.000000 -1.000000  C -1.000000  9.191265 -1.000000 -1.000000  2.301630   \n",
       "2  0.943877  5.310079  C  4.410969  5.326159  3.979592  3.928571  0.019645   \n",
       "\n",
       "          v9       v10    ...         v123      v124  v125      v126  \\\n",
       "0   9.999999  0.503281    ...     1.989780  0.035754    AU  1.804126   \n",
       "1  -1.000000  1.312910    ...    -1.000000  0.598896    AF -1.000000   \n",
       "2  12.666667  0.765864    ...     2.477596  0.013452    AE  1.773709   \n",
       "\n",
       "       v127      v128  v129      v130      v131  number_NAN  \n",
       "0  3.113719  2.024285     0  0.636365  2.857144           1  \n",
       "1 -1.000000  1.957825     0 -1.000000 -1.000000          81  \n",
       "2  3.922193  1.120468     2  0.883118  1.176472           2  \n",
       "\n",
       "[3 rows x 132 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add frequencies for object features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'v1', u'v2', u'v3', u'v4', u'v5', u'v6', u'v7', u'v8', u'v9', u'v10', u'v11', u'v12', u'v13', u'v14', u'v15', u'v16', u'v17', u'v18', u'v19', u'v20', u'v21', u'v22', u'v23', u'v24', u'v25', u'v26', u'v27', u'v28', u'v29', u'v30', u'v31', u'v32', u'v33', u'v34', u'v35', u'v36', u'v37', u'v38', u'v39', u'v40', u'v41', u'v42', u'v43', u'v44', u'v45', u'v46', u'v47', u'v48', u'v49', u'v50', u'v51', u'v52', u'v53', u'v54', u'v55', u'v56', u'v57', u'v58', u'v59', u'v60', u'v61', u'v62', u'v63', u'v64', u'v65', u'v66', u'v67', u'v68', u'v69', u'v70', u'v71', u'v72', u'v73', u'v74', u'v75', u'v76', u'v77', u'v78', u'v79', u'v80', u'v81', u'v82', u'v83', u'v84', u'v85', u'v86', u'v87', u'v88', u'v89', u'v90', u'v91', u'v92', u'v93', u'v94', u'v95', u'v96', u'v97', u'v98', u'v99', u'v100', ...], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_categories = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare data\n",
    "train_dummies = pd.DataFrame()\n",
    "test_dummies = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prob = train_with_target.groupby(['target']).size()[1]/float(sum(train_with_target.groupby(['target']).size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76119872989214576"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1\n",
      "v2\n",
      "v3\n",
      "v4\n",
      "v5\n",
      "v6\n",
      "v7\n",
      "v8\n",
      "v9\n",
      "v10\n",
      "v11\n",
      "v12\n",
      "v13\n",
      "v14\n",
      "v15\n",
      "v16\n",
      "v17\n",
      "v18\n",
      "v19\n",
      "v20\n",
      "v21\n",
      "v22\n",
      "v23\n",
      "v24\n",
      "v25\n",
      "v26\n",
      "v27\n",
      "v28\n",
      "v29\n",
      "v30\n",
      "v31\n",
      "v32\n",
      "v33\n",
      "v34\n",
      "v35\n",
      "v36\n",
      "v37\n",
      "v38\n",
      "v39\n",
      "v40\n",
      "v41\n",
      "v42\n",
      "v43\n",
      "v44\n",
      "v45\n",
      "v46\n",
      "v47\n",
      "v48\n",
      "v49\n",
      "v50\n",
      "v51\n",
      "v52\n",
      "v53\n",
      "v54\n",
      "v55\n",
      "v56\n",
      "v57\n",
      "v58\n",
      "v59\n",
      "v60\n",
      "v61\n",
      "v62\n",
      "v63\n",
      "v64\n",
      "v65\n",
      "v66\n",
      "v67\n",
      "v68\n",
      "v69\n",
      "v70\n",
      "v71\n",
      "v72\n",
      "v73\n",
      "v74\n",
      "v75\n",
      "v76\n",
      "v77\n",
      "v78\n",
      "v79\n",
      "v80\n",
      "v81\n",
      "v82\n",
      "v83\n",
      "v84\n",
      "v85\n",
      "v86\n",
      "v87\n",
      "v88\n",
      "v89\n",
      "v90\n",
      "v91\n",
      "v92\n",
      "v93\n",
      "v94\n",
      "v95\n",
      "v96\n",
      "v97\n",
      "v98\n",
      "v99\n",
      "v100\n",
      "v101\n",
      "v102\n",
      "v103\n",
      "v104\n",
      "v105\n",
      "v106\n",
      "v107\n",
      "v108\n",
      "v109\n",
      "v110\n",
      "v111\n",
      "v112\n",
      "v113\n",
      "v114\n",
      "v115\n",
      "v116\n",
      "v117\n",
      "v118\n",
      "v119\n",
      "v120\n",
      "v121\n",
      "v122\n",
      "v123\n",
      "v124\n",
      "v125\n",
      "v126\n",
      "v127\n",
      "v128\n",
      "v129\n",
      "v130\n",
      "v131\n"
     ]
    }
   ],
   "source": [
    "for elt in all_features:\n",
    "    vector = pd.concat([train[elt], test[elt]], axis = 0)\n",
    "    print str(elt)\n",
    "\n",
    "    if len(vector.unique()) < max_categories:\n",
    "        train_dummies = pd.concat([train_dummies, pd.get_dummies(train[elt], prefix = elt, \\\n",
    "                                                                 dummy_na = True)], axis = 1).astype('int8')\n",
    "        test_dummies = pd.concat([test_dummies, pd.get_dummies(test[elt], prefix = elt, \\\n",
    "                                                               dummy_na = True)], axis = 1).astype('int8')\n",
    "        del train[elt], test[elt]\n",
    "    else:\n",
    "        typ = str(train[elt].dtype)[:3]\n",
    "        if (typ == 'flo') or (typ == 'int'):\n",
    "            train[elt] = np.log(2 + train[elt])\n",
    "            test[elt] = np.log(2 + test[elt])\n",
    "        else:\n",
    "            if (typ == 'obj'):\n",
    "                list2keep = vector.value_counts()[ : max_categories].index\n",
    "                train[elt] = train[elt].apply(lambda x: x if x in list2keep else np.nan)\n",
    "                test[elt] = test[elt].apply(lambda x: x if x in list2keep else np.nan)                \n",
    "                train_dummies = pd.concat([train_dummies, pd.get_dummies(train[elt], prefix = elt, \\\n",
    "                                                                         dummy_na = True)], axis = 1).astype('int8')\n",
    "                test_dummies = pd.concat([test_dummies, pd.get_dummies(test[elt], prefix = elt, \\\n",
    "                                                                       dummy_na = True)], axis = 1).astype('int8')\n",
    "                \n",
    "                agrg = pd.concat([train[elt], target], axis = 1)\n",
    "                agrg = agrg.groupby(by = elt, axis = 0).agg(['sum','count']).target\n",
    "                agrg['weight'] = agrg.apply(lambda x: .5 + .5 * x['sum']/x['count'] if\\\n",
    "                                            (x['sum'] > x['count'] - x['sum']) else .5 + .5 * \\\n",
    "                                            (x['sum'] - x['count'])/x['count'], axis = 1)\n",
    "                agrg.reset_index(inplace = True)\n",
    "                train[elt + '_weight'] = pd.merge(train, agrg, how = 'left', on = elt)['weight']\n",
    "                test[elt + '_weight'] = pd.merge(test, agrg, how = 'left', on = elt)['weight']\n",
    "                train[elt + '_weight'] = train[elt + '_weight'].fillna(prob)\n",
    "                test[elt + '_weight'] = test[elt + '_weight'].fillna(prob)\n",
    "                del train[elt], test[elt]\n",
    "            else:\n",
    "                print('error', typ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>v10</th>\n",
       "      <th>v11</th>\n",
       "      <th>...</th>\n",
       "      <th>v123</th>\n",
       "      <th>v124</th>\n",
       "      <th>v126</th>\n",
       "      <th>v127</th>\n",
       "      <th>v128</th>\n",
       "      <th>v130</th>\n",
       "      <th>v131</th>\n",
       "      <th>number_NAN</th>\n",
       "      <th>v22_weight</th>\n",
       "      <th>v56_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 1.204694</td>\n",
       "      <td> 2.372808</td>\n",
       "      <td> 1.77851</td>\n",
       "      <td> 2.294076</td>\n",
       "      <td> 1.525899</td>\n",
       "      <td> 1.644205</td>\n",
       "      <td> 0.699597</td>\n",
       "      <td> 2.484907</td>\n",
       "      <td> 0.917602</td>\n",
       "      <td> 2.914203</td>\n",
       "      <td>...</td>\n",
       "      <td> 1.383736</td>\n",
       "      <td> 0.710866</td>\n",
       "      <td> 1.336086</td>\n",
       "      <td> 1.631927</td>\n",
       "      <td> 1.392347</td>\n",
       "      <td> 0.969401</td>\n",
       "      <td> 1.580451</td>\n",
       "      <td>  1</td>\n",
       "      <td> 0.761199</td>\n",
       "      <td> 0.930675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 0.00000</td>\n",
       "      <td> 2.415134</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 1.458994</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 1.197827</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 0.955087</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 1.375695</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 81</td>\n",
       "      <td> 0.761199</td>\n",
       "      <td> 0.930675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 1.079727</td>\n",
       "      <td> 1.989254</td>\n",
       "      <td> 1.85801</td>\n",
       "      <td> 1.991451</td>\n",
       "      <td> 1.788352</td>\n",
       "      <td> 1.779783</td>\n",
       "      <td> 0.702922</td>\n",
       "      <td> 2.685577</td>\n",
       "      <td> 1.017353</td>\n",
       "      <td> 2.818762</td>\n",
       "      <td>...</td>\n",
       "      <td> 1.499086</td>\n",
       "      <td> 0.699851</td>\n",
       "      <td> 1.328058</td>\n",
       "      <td> 1.778707</td>\n",
       "      <td> 1.137983</td>\n",
       "      <td> 1.058872</td>\n",
       "      <td> 1.155771</td>\n",
       "      <td>  2</td>\n",
       "      <td> 0.761199</td>\n",
       "      <td> 0.930675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         v1        v2       v4        v5        v6        v7        v8  \\\n",
       "0  1.204694  2.372808  1.77851  2.294076  1.525899  1.644205  0.699597   \n",
       "1  0.000000  0.000000  0.00000  2.415134  0.000000  0.000000  1.458994   \n",
       "2  1.079727  1.989254  1.85801  1.991451  1.788352  1.779783  0.702922   \n",
       "\n",
       "         v9       v10       v11    ...         v123      v124      v126  \\\n",
       "0  2.484907  0.917602  2.914203    ...     1.383736  0.710866  1.336086   \n",
       "1  0.000000  1.197827  0.000000    ...     0.000000  0.955087  0.000000   \n",
       "2  2.685577  1.017353  2.818762    ...     1.499086  0.699851  1.328058   \n",
       "\n",
       "       v127      v128      v130      v131  number_NAN  v22_weight  v56_weight  \n",
       "0  1.631927  1.392347  0.969401  1.580451           1    0.761199    0.930675  \n",
       "1  0.000000  1.375695  0.000000  0.000000          81    0.761199    0.930675  \n",
       "2  1.778707  1.137983  1.058872  1.155771           2    0.761199    0.930675  \n",
       "\n",
       "[3 rows x 111 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for elt in train.columns:\n",
    "    if (elt[-2:] == 'na') & (elt != 'v2_na'):\n",
    "        print str(elt)\n",
    "        dist = metrics.pairwise_distances(train.v2_na.reshape(1, -1), train[elt].reshape(1, -1))\n",
    "        if dist < 8:\n",
    "            del train[elt], test[elt]\n",
    "        else:\n",
    "            print(elt, dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.concat([train, train_dummies, target], axis = 1)\n",
    "test = pd.concat([test, test_dummies], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114321, 621)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for elt in list(set(train.columns) - set(test.columns)):\n",
    "    del train[elt]\n",
    "for elt in list(set(test.columns) - set(train.columns)):\n",
    "    del test[elt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tree blend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "skf = list(StratifiedKFold(target, n_folds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([ 22575,  22576,  22580, ..., 114318, 114319, 114320]),\n",
       "  array([    0,     1,     2, ..., 22961, 22962, 22964])),\n",
       " (array([     0,      1,      2, ..., 114318, 114319, 114320]),\n",
       "  array([22575, 22576, 22580, ..., 45728, 45729, 45731])),\n",
       " (array([     0,      1,      2, ..., 114318, 114319, 114320]),\n",
       "  array([45724, 45726, 45730, ..., 68871, 68875, 68882])),\n",
       " (array([     0,      1,      2, ..., 114318, 114319, 114320]),\n",
       "  array([68503, 68504, 68505, ..., 91556, 91559, 91560])),\n",
       " (array([    0,     1,     2, ..., 91556, 91559, 91560]),\n",
       "  array([ 91424,  91425,  91426, ..., 114318, 114319, 114320]))]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nclfs=[\\n    ensemble.ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='entropy',\\n           max_depth = None, max_features='sqrt', max_leaf_nodes=None,\\n           min_samples_leaf=1, min_samples_split=2,\\n           min_weight_fraction_leaf=1e-5, n_estimators = 1000, n_jobs=-1,\\n           oob_score=False, random_state=rnd, verbose=0, warm_start=False)\\n]\\n\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd = 57\n",
    "xgboost_params_1 = { \n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"booster\": \"gbtree\",\n",
    "        \"eval_metric\": \"auc\",\n",
    "        \"eta\": 0.01, # 0.06, #0.01,\n",
    "        \"min_child_weight\": 1,\n",
    "        \"subsample\": 0.8,\n",
    "        \"colsample_bytree\": 0.8,\n",
    "        \"max_depth\": 12,\n",
    "        'silent': 1,\n",
    "        'lambda': 0.5,\n",
    "        'gamma': 0.5\n",
    "    }\n",
    "\n",
    "xgboost_params_2 = { \n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"booster\": \"gbtree\",\n",
    "        \"eval_metric\": \"auc\",\n",
    "        \"eta\": 0.01, # 0.06, #0.01,\n",
    "        \"min_child_weight\": 1,\n",
    "        \"subsample\": 0.5,\n",
    "        \"colsample_bytree\": 0.5,\n",
    "        \"max_depth\": 12,\n",
    "        'silent': 1,\n",
    "        'lambda': 0.5,\n",
    "        'gamma': 0.5\n",
    "    }\n",
    "\n",
    "clfs=[\n",
    "    'xgboost-1',\n",
    "    'xgboost-2',\n",
    "    ensemble.RandomForestClassifier(bootstrap=False, class_weight='auto', criterion='entropy',\n",
    "            max_depth = None, max_features='sqrt', max_leaf_nodes=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators = 3000, n_jobs=-1,\n",
    "            oob_score=False, random_state=rnd, verbose=0,\n",
    "            warm_start=False),\n",
    "    ensemble.ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='entropy',\n",
    "           max_depth = None, max_features='sqrt', max_leaf_nodes=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=1e-5, n_estimators = 3000, n_jobs=-1,\n",
    "           oob_score=False, random_state=rnd, verbose=0, warm_start=False)\n",
    "]\n",
    "\n",
    "'''\n",
    "clfs=[\n",
    "    ensemble.ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='entropy',\n",
    "           max_depth = None, max_features='sqrt', max_leaf_nodes=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=1e-5, n_estimators = 1000, n_jobs=-1,\n",
    "           oob_score=False, random_state=rnd, verbose=0, warm_start=False)\n",
    "]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_rounds = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y, X_submission = train, target, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114393, 621)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train and test sets for blending.\n"
     ]
    }
   ],
   "source": [
    "print \"Creating train and test sets for blending.\"\n",
    "    \n",
    "dataset_blend_train = np.zeros((X.shape[0], len(clfs)))\n",
    "dataset_blend_test = np.zeros((X_submission.shape[0], len(clfs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for j, clf in enumerate(clfs):\n",
    "    print j, clf\n",
    "    dataset_blend_test_j = np.zeros((X_submission.shape[0], len(skf)))\n",
    "    for i, (train_idx, test_idx) in enumerate(skf):\n",
    "        print \"Fold: \", i\n",
    "        X_train = X.iloc[train_idx]\n",
    "        y_train = y.iloc[train_idx]\n",
    "        X_test = X.iloc[test_idx]\n",
    "        y_test = y.iloc[test_idx]\n",
    "        if clf == 'xgboost-1':\n",
    "            dtrain = xgb.DMatrix(X_train, label = y_train)\n",
    "            dcv = xgb.DMatrix(X_test, label = y_test)\n",
    "            clf_1 = xgb.train(xgboost_params_1, dtrain, num_boost_round = xgb_rounds)\n",
    "            y_submission = clf_1.predict(dcv, ntree_limit = clf_1.best_iteration)\n",
    "            dataset_blend_train[test_idx, j] = y_submission\n",
    "            dsub = xgb.DMatrix(X_submission)\n",
    "            dataset_blend_test_j[:, i] = clf_1.predict(dsub, ntree_limit = clf_1.best_iteration)\n",
    "        elif clf == 'xgboost-2':\n",
    "            dtrain = xgb.DMatrix(X_train, label = y_train)\n",
    "            dcv = xgb.DMatrix(X_test, label = y_test)\n",
    "            clf_1 = xgb.train(xgboost_params_2, dtrain, num_boost_round = xgb_rounds)\n",
    "            y_submission = clf_1.predict(dcv, ntree_limit = clf_1.best_iteration)\n",
    "            dataset_blend_train[test_idx, j] = y_submission\n",
    "            dsub = xgb.DMatrix(X_submission)\n",
    "            dataset_blend_test_j[:, i] = clf_1.predict(dsub, ntree_limit = clf_1.best_iteration)\n",
    "        else:\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_submission = clf.predict_proba(X_test)[:,1]\n",
    "            dataset_blend_train[test_idx, j] = y_submission\n",
    "            dataset_blend_test_j[:, i] = clf.predict_proba(X_submission)[:,1]\n",
    "        print \"log-loss: \" + str(metrics.log_loss(y_test, y_submission))\n",
    "    dataset_blend_test[:,j] = dataset_blend_test_j.mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print\n",
    "print \"Stacking...\"\n",
    "# clf = LogisticRegression()\n",
    "clf = ensemble.GradientBoostingClassifier(init = None, learning_rate = 0.1, loss = 'deviance',\n",
    "              max_depth = 12, max_features = None, max_leaf_nodes = None,\n",
    "              min_samples_leaf = 1, min_samples_split = 3,\n",
    "              min_weight_fraction_leaf = 0.0, n_estimators = 10,\n",
    "              random_state = rnd, subsample = 0.8, verbose = 0,\n",
    "              warm_start = False)\n",
    "clf.fit(dataset_blend_train, y)\n",
    "y_submission = clf.predict_proba(dataset_blend_test)[:, 1]\n",
    "\n",
    "print \"Linear stretch of predictions to [0,1]\"\n",
    "y_submission = (y_submission - y_submission.min()) / (y_submission.max() - y_submission.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(y_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# submit\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission.PredictedProb = y_submission\n",
    "submission.to_csv('stacking.csv', index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "stacking\n",
    "========================================\n",
    "max_categories: 20\n",
    "xgb-1: 0.01, 0.8, 0.8, 12, 0.5, 0.5, 1300\n",
    "xgb-2: 0.01, 0.6, 0.6, 12, 0.5, 0.5, 1300\n",
    "random forest: 1500 entropy/gini\n",
    "extra trees: 1500 entropy/gini\n",
    "\n",
    "cv log-loss:\n",
    "lb log-loss:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
